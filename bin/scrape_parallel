#!/usr/bin/env ruby

$:.unshift File.join(File.dirname(__FILE__), '..', 'lib')

require 'optparse'
require 'ostruct'
require 'sitemap_fetcher'
require 'webpage_mapper'
require 'webpage_indexer'
require 'csv'

class OptionsParser
  def self.parse(args)
    options = OpenStruct.new
    opt_parser = OptionParser.new do |opts|
      opts.banner = "Usage: scrape_parallel FILE_PATH [OPTIONS]"

      opts.on('-d', '--data_dir DATA_DIR',
              'Directory to store sitemaps') do |data_dir|
        options.data_dir = data_dir
      end

      opts.on('-c', '--count CONCURRENCY',
              'Number of websites to scrape in parallel (default: 5)') do |concurrency|
        options.concurrency = concurrency.to_i
        options.concurrency = 5 if options.concurrency == 0
      end

      opts.on_tail("-h", "--help", "Show this message") do
        puts opts
        exit
      end
    end
    opt_parser.parse!(args)
    options
  end
end

options = OptionsParser.parse(ARGV)
file_path = ARGV.pop
raise "Missing required FILE_PATH parameter" unless file_path
raise "Missing required DATA_DIR parameter" unless options.data_dir

rows = CSV.read(file_path)
header = rows.shift
sitemap_columns = header.each_index.select { |i| header[i] == 'sitemap' }

Parallel.each(rows, in_processes: options.concurrency) do |row|
  if header.index('website_url')
    url = row[header.index('website_url')]
    sitemaps = sitemap_columns.collect { |i| row[i] }.compact
    _options = options.dup
    _options.url_pattern = row[header.index('url_pattern')]
    _options.url_pattern = nil if _options.url_pattern == nil || _options.url_pattern.to_s.length == 0

    if sitemaps.empty? || sitemaps.all?(&:empty?)
      SitemapFetcher.new(url, _options).run!
      WebpageMapper.new(url, _options).run!
      WebpageIndexer.new(url, _options).run!
    else
      SitemapFetcher.new(url, _options).run! do |sitemaps_map|
        sitemaps_map.each do |digest, remote_url|
          if sitemaps.any? { |s| remote_url.match(/#{s}/) }
            _options.sitemap = digest
            WebpageMapper.new(url, _options).run!
            WebpageIndexer.new(url, _options).run!
          end
        end
      end
    end
  end
end
